{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Machine Learning Final Project\n",
        "=================================\n",
        "\n",
        "This project is the first leg of effort to translate to and from colloquial Arabic. In this project file, using a dataset from [Tatoeba](https://tatoeba.org/eng/downloads), we accomplished a model to translate to and from Modern Standard Arabic in an effort to lay the groundwork for colloquial corpora.\n",
        "\n"
      ]
    },
    {
      "source": [
        "## Imports and Intitializations ##\n",
        "\n",
        "Below are imports and intitializations for the project including the device: which determines which device the algorithm will be run on."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we are creating a language class, it holds attributes like the number of words, but also methods that convert words to and from indices. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since encoding with Arabic typically gets rid of the characters or augments text in a non-ideal fashion, we are just removing punctuation here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import unicodedata as ud\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Standardize strings and remove punctuation\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = s.lower().strip()\n",
        "    s = re.sub(r\"([?.!,؟'،])\", r\" \", s)\n",
        "    s = re.sub(r'[\" \"]+', \" \", s)\n",
        "    return s.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we read and preprocess the data we receive from the file. The reverse flag indicates Arabic to English if false and the opposite if true.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def readLines():\n",
        "    lines = open('./ara.txt', encoding='UTF-8').read().strip().split('\\n')\n",
        "    num_examples = len(lines)\n",
        "    pairs = [[w for w in l.split('\\t')][:2] for l in lines[:num_examples]]\n",
        "    data = pd.DataFrame(pairs, columns=[\"eng\", \"ar\"])\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')][:2] for l in lines]\n",
        "    return data, pairs\n",
        "\n",
        "def readLangs(reverse=True):\n",
        "    data, pairs = readLines()\n",
        "\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(data['eng'])\n",
        "        output_lang = Lang(data['ar'])\n",
        "    else:\n",
        "        input_lang = Lang(data['ar'])\n",
        "        output_lang = Lang(data['eng'])\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The logic below prints test data to visualize what's loaded in the above step. It also prepares data for next step of model process.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 11584 sentence pairs\nNumber of words:\n0                                                      Hi.\n1                                                     Run!\n2                                                    Help!\n3                                                    Jump!\n4                                                    Stop!\n                               ...                        \n11579    I'll be playing tennis with Tom this afternoon...\n11580    The mobile phone you have dialed is either swi...\n11581    A man touched down on the moon. A wall came do...\n11582    Ladies and gentlemen, please stand for the nat...\n11583    There are mothers and fathers who will lie awa...\nName: eng, Length: 11584, dtype: object 11982\n0                                                  مرحبًا.\n1                                                    اركض!\n2                                                  النجدة!\n3                                                    اقفز!\n4                                                      قف!\n                               ...                        \n11579    أنا سوف ألعب تنس مع توم بعد الظهر, لكن هذا لا ...\n11580    الهاتف المتحرك الذي طلبته مغلق أو خارج نطاق ال...\n11581    هبط إنسان على سطح القمر، وأنهار حائط في برلين،...\n11582    سيداتي و سادتي ، رجاءً قفوا للنشيد الوطني للات...\n11583    وهناك أمهات وآباء سيظلون مستيقظين بعد أن ينام ...\nName: ar, Length: 11584, dtype: object 4182\n"
          ]
        }
      ],
      "source": [
        "def prepareData(lang1, lang2, reverse=True):\n",
        "    input_lang, output_lang, pairs = readLangs(reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Number of words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('ar', 'eng')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Seq2Seq Modeling ##\n",
        "\n",
        "With this Seq2Seq model (or encoder and decoder model), the encoder is designed for an input sequence to output a vector with logic, and the decoder reads that vector and produces the output sentence or \"guess\". A Seq2Seq model encoder encodes the \"meaning\" of the sentence unlike a single RNN. This fact is ideal for langauge translation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Encoder ###\n",
        "\n",
        "The encoder outputs the vector stated above alongside the hidden state, a variable used for the next word and iteration through the encoder.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Decoder ###\n",
        "As opposed to a simple decoder, we will use an attention decoder to decipher encoder vectors. With an attention decoder, the network is able to \"attend to\" specific portions of encoder returns and formulate a more context driven result. Below is logic and attention weights recommended by pytorch in an example they have given.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 11584\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the Model ##\n",
        "\n",
        "Here, we train out model and keep track of outputs and hidden states. The decoder first receives the ``<SOS>`` token as first input na dhidden state of encoder as first hidden state. We move along in the training process by teacher forcing, decided by an if-statement below. Teacher forcing is using the actual target output as enxt input instead of value that the encoder produces. It should speed up model convergence.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]\n",
        "\n",
        "    else:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These helper methods just aid the output produce estimated and elapsed time values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below is a pretty simple iterator that loops through our training data and displays progress information on time and loss values.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0 \n",
        "    plot_loss_total = 0 \n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation ##\n",
        "\n",
        "In the evaluation stage, logic is quite similar to training other than the lack of targets. Here we geed decoder predictions back to model in each step to evaluate accuracy. This portion also allows us to visualize tangible results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The method below allows results to be visualized by user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('original >', pair[0])\n",
        "        print('correct =', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('prediction <', output_sentence[:-6])\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and Evaluating ##\n",
        "\n",
        "To mitigate long training times and lack of access to great hardware, we use the parameters below to evaluate the model. After an initial run, the first 3 lines may be commented out to further train the same model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1m 47s (- 34m 11s) (5000 5%) 4.5446\n",
            "3m 22s (- 30m 23s) (10000 10%) 4.1693\n",
            "5m 1s (- 28m 25s) (15000 15%) 3.8820\n",
            "6m 39s (- 26m 39s) (20000 20%) 3.6218\n",
            "8m 19s (- 24m 58s) (25000 25%) 3.3905\n",
            "9m 59s (- 23m 18s) (30000 30%) 3.2034\n",
            "11m 40s (- 21m 40s) (35000 35%) 2.9978\n",
            "13m 23s (- 20m 5s) (40000 40%) 2.8222\n",
            "15m 7s (- 18m 29s) (45000 45%) 2.6367\n",
            "16m 53s (- 16m 53s) (50000 50%) 2.5064\n",
            "18m 35s (- 15m 13s) (55000 55%) 2.3312\n",
            "20m 17s (- 13m 31s) (60000 60%) 2.2024\n",
            "21m 56s (- 11m 48s) (65000 65%) 2.0966\n",
            "23m 39s (- 10m 8s) (70000 70%) 2.0333\n",
            "25m 19s (- 8m 26s) (75000 75%) 1.8791\n",
            "27m 8s (- 6m 47s) (80000 80%) 1.7753\n",
            "29m 29s (- 5m 12s) (85000 85%) 1.7247\n",
            "32m 8s (- 3m 34s) (90000 90%) 1.6205\n",
            "34m 41s (- 1m 49s) (95000 95%) 1.5317\n",
            "37m 17s (- 0m 0s) (100000 100%) 1.5143\n"
          ]
        }
      ],
      "source": [
        "# hidden_size = 256\n",
        "# encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "# attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 100000, print_every=5000)"
      ]
    },
    {
      "source": [
        "Below are actual predictions by machine as indicated in print."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original > صومطرة جزيرةٌ\n",
            "correct = sumatra is an island\n",
            "prediction < sumatra is an island\n",
            "\n",
            "original > أُنظر إلى هذا\n",
            "correct = look at this\n",
            "prediction < look at this\n",
            "\n",
            "original > يجب عليك الانضمام لي\n",
            "correct = you must join me\n",
            "prediction < you must join me\n",
            "\n",
            "original > بإمكان هذا الطفل أن يعد إلى مئة مع أنه ما زال لديه أربع سنوات\n",
            "correct = that child is only four but he can already count to 100\n",
            "prediction < the only is is but is is is he is that he is\n",
            "\n",
            "original > كل ما عليك فعله هو أن تسمع بعناية\n",
            "correct = all you need to do is listen carefully\n",
            "prediction < all all you need is is is to you\n",
            "\n",
            "original > أنت لم تتغير مُطلقاً\n",
            "correct = you haven t changed at all\n",
            "prediction < you haven t changed all all all\n",
            "\n",
            "original > لا تنس إخراج القمامة\n",
            "correct = don t forget to take out the garbage\n",
            "prediction < don t forget the card\n",
            "\n",
            "original > أنا طالب\n",
            "correct = i m a student\n",
            "prediction < i m a student\n",
            "\n",
            "original > أسعدتني رسالتك\n",
            "correct = your letter made me happy\n",
            "prediction < your letter made me\n",
            "\n",
            "original > سيأتي الربيع قريباً\n",
            "correct = spring will come soon\n",
            "prediction < will will will soon soon\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}