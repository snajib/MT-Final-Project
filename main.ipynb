{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Machine Learning Final Project\n",
        "=================================\n",
        "\n",
        "This project is the first leg of effort to translate to and from colloquial Arabic. In this project file, using a dataset from [Tatoeba](https://tatoeba.org/eng/downloads), we accomplished a model to translate to and from Modern Standard Arabic in an effort to lay the groundwork for colloquial corpora.\n",
        "\n"
      ]
    },
    {
      "source": [
        "## Imports and Intitializations ##\n",
        "\n",
        "Below are imports and intitializations for the project including the device: which determines which device the algorithm will be run on."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we are creating a language class, it holds attributes like the number of words, but also methods that convert words to and from indices. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since encoding with Arabic typically gets rid of the characters or augments text in a non-ideal fashion, we are just removing punctuation here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import unicodedata as ud\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Standardize strings and remove punctuation\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = s.lower().strip()\n",
        "    s = re.sub(r\"([?.!,؟'،])\", r\" \", s)\n",
        "    s = re.sub(r'[\" \"]+', \" \", s)\n",
        "    return s.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we read and preprocess the data we receive from the file. The reverse flag indicates Arabic to English if false and the opposite if true.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def readLines():\n",
        "    lines = open('./ara.txt', encoding='UTF-8').read().strip().split('\\n')\n",
        "    num_examples = len(lines)\n",
        "    pairs = [[w for w in l.split('\\t')][:2] for l in lines[:num_examples]]\n",
        "    data = pd.DataFrame(pairs, columns=[\"eng\", \"ar\"])\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')][:2] for l in lines]\n",
        "    return data, pairs\n",
        "\n",
        "def readLangs(reverse=True):\n",
        "    data, pairs = readLines()\n",
        "\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(data['eng'])\n",
        "        output_lang = Lang(data['ar'])\n",
        "    else:\n",
        "        input_lang = Lang(data['ar'])\n",
        "        output_lang = Lang(data['eng'])\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The logic below prints test data to visualize what's loaded in the above step. It also prepares data for next step of model process.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 11584 sentence pairs\nNumber of words:\n0                                                      Hi.\n1                                                     Run!\n2                                                    Help!\n3                                                    Jump!\n4                                                    Stop!\n                               ...                        \n11579    I'll be playing tennis with Tom this afternoon...\n11580    The mobile phone you have dialed is either swi...\n11581    A man touched down on the moon. A wall came do...\n11582    Ladies and gentlemen, please stand for the nat...\n11583    There are mothers and fathers who will lie awa...\nName: eng, Length: 11584, dtype: object 11982\n0                                                  مرحبًا.\n1                                                    اركض!\n2                                                  النجدة!\n3                                                    اقفز!\n4                                                      قف!\n                               ...                        \n11579    أنا سوف ألعب تنس مع توم بعد الظهر, لكن هذا لا ...\n11580    الهاتف المتحرك الذي طلبته مغلق أو خارج نطاق ال...\n11581    هبط إنسان على سطح القمر، وأنهار حائط في برلين،...\n11582    سيداتي و سادتي ، رجاءً قفوا للنشيد الوطني للات...\n11583    وهناك أمهات وآباء سيظلون مستيقظين بعد أن ينام ...\nName: ar, Length: 11584, dtype: object 4182\n"
          ]
        }
      ],
      "source": [
        "def prepareData(lang1, lang2, reverse=True):\n",
        "    input_lang, output_lang, pairs = readLangs(reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Number of words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('ar', 'eng')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Seq2Seq Modeling ##\n",
        "\n",
        "With this Seq2Seq model (or encoder and decoder model), the encoder is designed for an input sequence to output a vector with logic, and the decoder reads that vector and produces the output sentence or \"guess\". A Seq2Seq model encoder encodes the \"meaning\" of the sentence unlike a single RNN. This fact is ideal for langauge translation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Encoder ###\n",
        "\n",
        "The encoder outputs the vector stated above alongside the hidden state, a variable used for the next word and iteration through the encoder.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Decoder ###\n",
        "As opposed to a simple decoder, we will use an attention decoder to decipher encoder vectors. With an attention decoder, the network is able to \"attend to\" specific portions of encoder returns and formulate a more context driven result. Below is logic and attention weights recommended by pytorch in an example they have given.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 11584\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the Model ##\n",
        "\n",
        "Here, we train out model and keep track of outputs and hidden states. The decoder first receives the ``<SOS>`` token as first input na dhidden state of encoder as first hidden state. We move along in the training process by teacher forcing, decided by an if-statement below. Teacher forcing is using the actual target output as enxt input instead of value that the encoder produces. It should speed up model convergence.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]\n",
        "\n",
        "    else:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These helper methods just aid the output produce estimated and elapsed time values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below is a pretty simple iterator that loops through our training data and displays progress information on time and loss values.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0 \n",
        "    plot_loss_total = 0 \n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation ##\n",
        "\n",
        "In the evaluation stage, logic is quite similar to training other than the lack of targets. Here we geed decoder predictions back to model in each step to evaluate accuracy. This portion also allows us to visualize tangible results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The method below allows results to be visualized by user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('original >', pair[0])\n",
        "        print('correct =', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('prediction <', output_sentence[:-6])\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and Evaluating ##\n",
        "\n",
        "To mitigate long training times and lack of access to great hardware, we use the parameters below to evaluate the model. After an initial run, the first 3 lines may be commented out to further train the same model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1m 59s (- 37m 53s) (5000 5%) 1.4417\n",
            "3m 46s (- 33m 58s) (10000 10%) 1.3661\n",
            "5m 32s (- 31m 26s) (15000 15%) 1.3279\n",
            "7m 20s (- 29m 20s) (20000 20%) 1.2769\n",
            "9m 6s (- 27m 18s) (25000 25%) 1.2414\n",
            "10m 57s (- 25m 33s) (30000 30%) 1.1644\n",
            "12m 45s (- 23m 42s) (35000 35%) 1.1280\n",
            "14m 31s (- 21m 46s) (40000 40%) 1.0760\n",
            "16m 19s (- 19m 57s) (45000 45%) 1.0634\n",
            "18m 6s (- 18m 6s) (50000 50%) 1.0499\n",
            "19m 53s (- 16m 16s) (55000 55%) 0.9748\n",
            "21m 40s (- 14m 26s) (60000 60%) 0.9892\n",
            "23m 26s (- 12m 37s) (65000 65%) 0.9510\n",
            "25m 13s (- 10m 48s) (70000 70%) 0.9800\n",
            "26m 59s (- 8m 59s) (75000 75%) 0.9394\n",
            "28m 45s (- 7m 11s) (80000 80%) 0.9339\n",
            "30m 32s (- 5m 23s) (85000 85%) 0.9012\n",
            "32m 18s (- 3m 35s) (90000 90%) 0.8803\n",
            "34m 4s (- 1m 47s) (95000 95%) 0.8392\n",
            "35m 50s (- 0m 0s) (100000 100%) 0.8387\n"
          ]
        }
      ],
      "source": [
        "# hidden_size = 256\n",
        "# encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "# attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 100000, print_every=5000)"
      ]
    },
    {
      "source": [
        "Below are actual predictions by machine as indicated in print."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original > يجب علي أن أذهب الآن\n",
            "correct = i have to go now\n",
            "prediction < i have to go now\n",
            "\n",
            "original > سيهرب توم\n",
            "correct = tom will escape\n",
            "prediction < tom will escape\n",
            "\n",
            "original > إن ذلك مستحيل\n",
            "correct = it s impossible\n",
            "prediction < it s impossible\n",
            "\n",
            "original > أتعلم أين هي محطّة الشّرطة\n",
            "correct = do you know where the police station is\n",
            "prediction < do you know where the police station\n",
            "\n",
            "original > كنت محقا قطعا\n",
            "correct = you were absolutely right\n",
            "prediction < you were absolutely right\n",
            "\n",
            "original > لم أستطع أن آتي بسبب المطر الغزير\n",
            "correct = i could not come because of the heavy rain\n",
            "prediction < i could not come because of the heavy\n",
            "\n",
            "original > لم أسرق المال\n",
            "correct = i didn t steal the money\n",
            "prediction < i didn t steal the money\n",
            "\n",
            "original > يمكن أن تحدث الزلازل في أي لحظة\n",
            "correct = earthquakes may occur at any moment\n",
            "prediction < earthquakes may moment moment moment\n",
            "\n",
            "original > سترى الفرق\n",
            "correct = you will see the difference\n",
            "prediction < you will see the difference\n",
            "\n",
            "original > إنهم يعشقون موسيقى الجاز بجنون\n",
            "correct = they are crazy about jazz\n",
            "prediction < they are crazy about jazz\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}